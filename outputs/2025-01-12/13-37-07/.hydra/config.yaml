task_name: ${experiment.task_name}
data:
  task: ${task_name}
  batch_size: 1024
  num_workers: 8
  seed: 420
  alphabet: ARNDCQEGHILKMFPSTWYV
  sequence_column: sequence
  weighted_sampling: true
model:
  optimizer:
    lr: 0.0001
    weight_decay: 0.0001
callbacks:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: ${global_paths.root_dir}/ckpt/${data.task}
  filename: epoch_{epoch:03d}
  monitor: train_sr
  mode: max
  save_top_k: 1
  save_last: true
trainer:
  max_epochs: 100
  accelerator: gpu
  log_every_n_steps: 1
global_paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  data_dir: ${global_paths.root_dir}/data/
experiment:
  task_name: GFP
  gfp:
    csv_path: ${global_paths.data_dir}/GFP/ground_truth.csv
    task_dir: ${global_paths.data_dir}/GFP
    filter_per:
    - 0.0
    - 0.3
    min_mutant_dist: 7
    top_quantile: 0.99
    pin_memory: true
